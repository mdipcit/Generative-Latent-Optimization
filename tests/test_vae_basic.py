#!/usr/bin/env python3
"""
SD 1.4 VAEÂü∫Êú¨Âãï‰ΩúÁ¢∫Ë™ç„Çπ„ÇØ„É™„Éó„Éà
ÁõÆÁöÑÔºöDiffusers„É©„Ç§„Éñ„É©„É™„ÅåÊ≠£„Åó„ÅèÂãï‰Ωú„Åô„Çã„Åì„Å®„ÇíÁ¢∫Ë™ç
"""

import torch
from diffusers import AutoencoderKL
import numpy as np
import time

def test_model_loading():
    """SD 1.4 VAE„É¢„Éá„É´„ÅåÊ≠£„Åó„ÅèË™≠„ÅøËæº„ÇÅ„Çã„Åã„ÉÜ„Çπ„Éà"""
    print("=" * 50)
    print("TEST 1: Model Loading")
    print("=" * 50)
    
    try:
        vae = AutoencoderKL.from_pretrained(
            "CompVis/stable-diffusion-v1-4",
            subfolder="vae",
            token="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",
        )
        print("‚úÖ Model loaded successfully")
        print(f"   Model config scaling factor: {vae.config.scaling_factor}")
        print(f"   Model device: {vae.device}")
        print(f"   Model dtype: {next(vae.parameters()).dtype}")
        return vae
        
    except Exception as e:
        print(f"‚ùå Model loading failed: {e}")
        return None

def test_encode_decode_shapes(vae):
    """„Ç®„É≥„Ç≥„Éº„Éâ„Éª„Éá„Ç≥„Éº„Éâ„ÅÆÂΩ¢Áä∂„ÅåÊ≠£„Åó„ÅÑ„Åã„ÉÜ„Çπ„Éà"""
    print("\n" + "=" * 50)
    print("TEST 2: Shape Validation")
    print("=" * 50)
    
    # „ÉÜ„Çπ„ÉàÁî®„É©„É≥„ÉÄ„É†ÁîªÂÉè (512x512x3, [-1,1] range)
    batch_size = 2
    test_images = torch.randn(batch_size, 3, 512, 512) * 2 - 1
    test_images = test_images.clamp(-1, 1)
    
    print(f"Input shape: {test_images.shape}")
    print(f"Input range: [{test_images.min():.3f}, {test_images.max():.3f}]")
    
    try:
        # „Ç®„É≥„Ç≥„Éº„Éâ
        with torch.no_grad():
            posterior = vae.encode(test_images)
            latents = posterior.latent_dist.mode()
            scaled_latents = latents * vae.config.scaling_factor
            
        print(f"‚úÖ Encode successful")
        print(f"   Latent shape: {latents.shape}")
        print(f"   Expected shape: ({batch_size}, 4, 64, 64)")
        print(f"   Latent range (raw): [{latents.min():.3f}, {latents.max():.3f}]")
        print(f"   Scaled latent range: [{scaled_latents.min():.3f}, {scaled_latents.max():.3f}]")
        
        # ÂΩ¢Áä∂Á¢∫Ë™ç
        expected_shape = (batch_size, 4, 64, 64)
        if latents.shape == expected_shape:
            print("‚úÖ Latent shape correct")
        else:
            print(f"‚ùå Latent shape incorrect. Got {latents.shape}, expected {expected_shape}")
            
    except Exception as e:
        print(f"‚ùå Encode failed: {e}")
        return None, None
    
    try:
        # „Éá„Ç≥„Éº„Éâ
        with torch.no_grad():
            decoded_images = vae.decode(latents).sample
            
        print(f"‚úÖ Decode successful")
        print(f"   Decoded shape: {decoded_images.shape}")
        print(f"   Decoded range: [{decoded_images.min():.3f}, {decoded_images.max():.3f}]")
        
        # ÂΩ¢Áä∂Á¢∫Ë™ç
        if decoded_images.shape == test_images.shape:
            print("‚úÖ Decoded shape correct")
        else:
            print(f"‚ùå Decoded shape incorrect")
            
        return test_images, decoded_images
        
    except Exception as e:
        print(f"‚ùå Decode failed: {e}")
        return test_images, None

def test_reconstruction_quality(original, reconstructed):
    """ÂÜçÊßãÊàêÂìÅË≥™„ÅÆÂü∫Êú¨„ÉÅ„Çß„ÉÉ„ÇØ"""
    print("\n" + "=" * 50)
    print("TEST 3: Reconstruction Quality")
    print("=" * 50)
    
    if reconstructed is None:
        print("‚ùå No reconstructed image to test")
        return
    
    # MSEÊêçÂ§±Ë®àÁÆó
    mse_loss = torch.nn.functional.mse_loss(original, reconstructed)
    print(f"MSE Loss: {mse_loss.item():.6f}")
    
    # MAEÊêçÂ§±Ë®àÁÆó
    mae_loss = torch.nn.functional.l1_loss(original, reconstructed)
    print(f"MAE Loss: {mae_loss.item():.6f}")
    
    # ÂÄ§ÁØÑÂõ≤„ÉÅ„Çß„ÉÉ„ÇØ
    if torch.all(reconstructed >= -1.2) and torch.all(reconstructed <= 1.2):
        print("‚úÖ Output range within expected bounds [-1.2, 1.2]")
    else:
        print(f"‚ùå Output range issue: [{reconstructed.min():.3f}, {reconstructed.max():.3f}]")
    
    # Âü∫Êú¨ÁöÑ„Å™ÂìÅË≥™ÊåáÊ®ô
    if mse_loss < 1.0:  # ÁµåÈ®ìÁöÑ„Å™ÈñæÂÄ§
        print("‚úÖ Reconstruction quality acceptable (MSE < 1.0)")
    else:
        print("‚ö†Ô∏è  High reconstruction error - check model/input")
    
    # PSNRË®àÁÆóÔºàÂèÇËÄÉÂÄ§Ôºâ
    psnr = 20 * torch.log10(2.0 / torch.sqrt(mse_loss))
    print(f"PSNR: {psnr.item():.2f} dB")

def test_different_input_sizes(vae):
    """Áï∞„Å™„ÇãÂÖ•Âäõ„Çµ„Ç§„Ç∫„Åß„ÅÆÂãï‰ΩúÁ¢∫Ë™ç"""
    print("\n" + "=" * 50)
    print("TEST 4: Input Size Validation")
    print("=" * 50)
    
    test_sizes = [
        (1, 3, 512, 512),   # Ê≠£Â∏∏„Çµ„Ç§„Ç∫
        (1, 3, 256, 256),   # Â∞è„Åï„ÅÑ„Çµ„Ç§„Ç∫
        (4, 3, 512, 512),   # „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫4
    ]
    
    for size in test_sizes:
        try:
            test_input = torch.randn(*size).clamp(-1, 1)
            with torch.no_grad():
                latents = vae.encode(test_input).latent_dist.mode()
                decoded = vae.decode(latents).sample
            
            expected_latent_h = size[2] // 8  # VAE„ÅØ8ÂÄç„ÉÄ„Ç¶„É≥„Çµ„É≥„Éó„É´
            expected_latent_w = size[3] // 8
            
            if latents.shape == (size[0], 4, expected_latent_h, expected_latent_w):
                print(f"‚úÖ Size {size}: Latent shape {latents.shape}")
            else:
                print(f"‚ùå Size {size}: Unexpected latent shape {latents.shape}")
                
        except Exception as e:
            print(f"‚ùå Size {size}: Failed - {e}")

def test_device_compatibility(vae):
    """CPU/CUDA‰∫íÊèõÊÄß„ÉÜ„Çπ„Éà"""
    print("\n" + "=" * 50)
    print("TEST 5: Device Compatibility")
    print("=" * 50)
    
    test_input = torch.randn(1, 3, 512, 512).clamp(-1, 1)
    
    # CPU „ÉÜ„Çπ„Éà
    try:
        vae_cpu = vae.to('cpu')
        test_input_cpu = test_input.to('cpu')
        
        start_time = time.time()
        with torch.no_grad():
            latents = vae_cpu.encode(test_input_cpu).latent_dist.mode()
            decoded = vae_cpu.decode(latents).sample
        cpu_time = time.time() - start_time
            
        print(f"‚úÖ CPU execution successful ({cpu_time:.3f}s)")
        
    except Exception as e:
        print(f"‚ùå CPU execution failed: {e}")
    
    # CUDA „ÉÜ„Çπ„ÉàÔºàÂà©Áî®ÂèØËÉΩ„Å™Â†¥ÂêàÔºâ
    if torch.cuda.is_available():
        try:
            vae_cuda = vae.to('cuda')
            test_input_cuda = test_input.to('cuda')
            
            start_time = time.time()
            with torch.no_grad():
                latents = vae_cuda.encode(test_input_cuda).latent_dist.mode()
                decoded = vae_cuda.decode(latents).sample
            gpu_time = time.time() - start_time
                
            print(f"‚úÖ CUDA execution successful ({gpu_time:.3f}s)")
            
            if cpu_time > 0:
                speedup = cpu_time / gpu_time
                print(f"   GPU speedup: {speedup:.1f}x")
            
        except Exception as e:
            print(f"‚ùå CUDA execution failed: {e}")
    else:
        print("‚ö†Ô∏è  CUDA not available, skipping GPU test")

def test_scaling_factor_validation(vae):
    """SD 1.4 „Çπ„Ç±„Éº„É™„É≥„Ç∞„Éï„Ç°„ÇØ„Çø„Éº„ÅÆÊ≠£Á¢∫ÊÄß„ÉÜ„Çπ„Éà"""
    print("\n" + "=" * 50)
    print("TEST 6: Scaling Factor Validation")
    print("=" * 50)
    
    test_input = torch.randn(1, 3, 512, 512).clamp(-1, 1)
    
    try:
        with torch.no_grad():
            # Diffusers„ÅÆÊ®ôÊ∫ñ„Ç®„É≥„Ç≥„Éº„Éâ
            posterior = vae.encode(test_input)
            latents_mode = posterior.latent_dist.mode()
            
            # „Çπ„Ç±„Éº„É™„É≥„Ç∞„Éï„Ç°„ÇØ„Çø„ÉºÁ¢∫Ë™ç
            expected_scaling = 0.18215
            actual_scaling = vae.config.scaling_factor
            
            print(f"Expected scaling factor: {expected_scaling}")
            print(f"Actual scaling factor: {actual_scaling}")
            
            if abs(actual_scaling - expected_scaling) < 1e-5:
                print("‚úÖ Scaling factor matches SD 1.4 specification")
            else:
                print("‚ö†Ô∏è  Scaling factor differs from expected")
            
            # „Çπ„Ç±„Éº„É™„É≥„Ç∞ÈÅ©Áî®„ÉÜ„Çπ„Éà
            scaled_latents = latents_mode * actual_scaling
            print(f"Raw latent range: [{latents_mode.min():.3f}, {latents_mode.max():.3f}]")
            print(f"Scaled latent range: [{scaled_latents.min():.3f}, {scaled_latents.max():.3f}]")
            
    except Exception as e:
        print(f"‚ùå Scaling factor test failed: {e}")

def main():
    """„É°„Ç§„É≥Ê§úË®ºÂÆüË°å"""
    print("üß™ SD 1.4 VAE Library Verification")
    print("Purpose: Verify Diffusers library works correctly")
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA version: {torch.version.cuda}")
        print(f"GPU: {torch.cuda.get_device_name()}")
    print()
    
    # 1. „É¢„Éá„É´Ë™≠„ÅøËæº„Åø
    vae = test_model_loading()
    if vae is None:
        print("\n‚ùå Critical failure: Cannot proceed without model")
        return False
    
    # 2. Âü∫Êú¨ÁöÑ„Å™„Ç®„É≥„Ç≥„Éº„Éâ„Éª„Éá„Ç≥„Éº„Éâ
    original, reconstructed = test_encode_decode_shapes(vae)
    
    # 3. ÂÜçÊßãÊàêÂìÅË≥™„ÉÅ„Çß„ÉÉ„ÇØ  
    test_reconstruction_quality(original, reconstructed)
    
    # 4. Áï∞„Å™„ÇãÂÖ•Âäõ„Çµ„Ç§„Ç∫„ÉÜ„Çπ„Éà
    test_different_input_sizes(vae)
    
    # 5. „Éá„Éê„Ç§„Çπ‰∫íÊèõÊÄß
    test_device_compatibility(vae)
    
    # 6. „Çπ„Ç±„Éº„É™„É≥„Ç∞„Éï„Ç°„ÇØ„Çø„ÉºÊ§úË®º
    test_scaling_factor_validation(vae)
    
    print("\n" + "=" * 50)
    print("üèÅ VERIFICATION COMPLETE")
    print("=" * 50)
    print("If all tests show ‚úÖ, the library is working correctly.")
    print("If any test shows ‚ùå, there may be an issue with:")
    print("  - Installation")
    print("  - Authentication token") 
    print("  - System configuration")
    print("  - GPU drivers (for CUDA tests)")
    
    return True

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)