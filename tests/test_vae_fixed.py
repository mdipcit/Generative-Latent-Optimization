#!/usr/bin/env python3
"""
SD 1.4 VAEä¿®æ­£ç‰ˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œã‚’ä¿®æ­£ã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³
"""

import torch
from diffusers import AutoencoderKL
import numpy as np
import time

def test_model_loading():
    """SD 1.4 VAEãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãèª­ã¿è¾¼ã‚ã‚‹ã‹ãƒ†ã‚¹ãƒˆ"""
    print("=" * 50)
    print("TEST 1: Model Loading (Fixed)")
    print("=" * 50)
    
    try:
        vae = AutoencoderKL.from_pretrained(
            "CompVis/stable-diffusion-v1-4",
            subfolder="vae",
            token="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",
        )
        
        # GPUãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯è‡ªå‹•çš„ã«ç§»å‹•
        if torch.cuda.is_available():
            vae = vae.cuda()
            print("âœ… Model moved to GPU")
        else:
            print("âœ… Model on CPU")
            
        print(f"   Model config scaling factor: {vae.config.scaling_factor}")
        print(f"   Model device: {next(vae.parameters()).device}")
        print(f"   Model dtype: {next(vae.parameters()).dtype}")
        return vae
        
    except Exception as e:
        print(f"âŒ Model loading failed: {e}")
        return None

def test_encode_decode_with_clamping(vae):
    """å‡ºåŠ›ç¯„å›²åˆ¶é™ä»˜ãã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 50)
    print("TEST 2: Shape Validation (With Clamping)")
    print("=" * 50)
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒ (512x512x3, [-1,1] range)
    batch_size = 2
    device = next(vae.parameters()).device
    
    test_images = torch.randn(batch_size, 3, 512, 512).clamp(-1, 1).to(device)
    
    print(f"Input shape: {test_images.shape}")
    print(f"Input range: [{test_images.min():.3f}, {test_images.max():.3f}]")
    print(f"Input device: {test_images.device}")
    
    try:
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        with torch.no_grad():
            posterior = vae.encode(test_images)
            latents = posterior.latent_dist.mode()
            scaled_latents = latents * vae.config.scaling_factor
            
        print(f"âœ… Encode successful")
        print(f"   Latent shape: {latents.shape}")
        print(f"   Expected shape: ({batch_size}, 4, 64, 64)")
        print(f"   Latent range (raw): [{latents.min():.3f}, {latents.max():.3f}]")
        print(f"   Scaled latent range: [{scaled_latents.min():.3f}, {scaled_latents.max():.3f}]")
        
        # å½¢çŠ¶ç¢ºèª
        expected_shape = (batch_size, 4, 64, 64)
        if latents.shape == expected_shape:
            print("âœ… Latent shape correct")
        else:
            print(f"âŒ Latent shape incorrect. Got {latents.shape}, expected {expected_shape}")
            
    except Exception as e:
        print(f"âŒ Encode failed: {e}")
        return None, None
    
    try:
        # ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆå‡ºåŠ›ç¯„å›²åˆ¶é™ä»˜ãï¼‰
        with torch.no_grad():
            decoded_images = vae.decode(latents).sample
            # æ˜ç¤ºçš„ã«[-1, 1]ç¯„å›²ã«ã‚¯ãƒ©ãƒ³ãƒ—
            decoded_images_clamped = decoded_images.clamp(-1, 1)
            
        print(f"âœ… Decode successful")
        print(f"   Decoded shape: {decoded_images.shape}")
        print(f"   Raw decoded range: [{decoded_images.min():.3f}, {decoded_images.max():.3f}]")
        print(f"   Clamped decoded range: [{decoded_images_clamped.min():.3f}, {decoded_images_clamped.max():.3f}]")
        
        # å½¢çŠ¶ç¢ºèª
        if decoded_images_clamped.shape == test_images.shape:
            print("âœ… Decoded shape correct")
        else:
            print(f"âŒ Decoded shape incorrect")
        
        # ç¯„å›²ãƒã‚§ãƒƒã‚¯
        if torch.all(decoded_images_clamped >= -1.0) and torch.all(decoded_images_clamped <= 1.0):
            print("âœ… Output range properly clamped to [-1, 1]")
        else:
            print("âŒ Clamping failed")
            
        return test_images, decoded_images_clamped
        
    except Exception as e:
        print(f"âŒ Decode failed: {e}")
        return test_images, None

def test_proper_device_handling(vae):
    """é©åˆ‡ãªãƒ‡ãƒã‚¤ã‚¹å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 50)
    print("TEST 3: Proper Device Handling")
    print("=" * 50)
    
    model_device = next(vae.parameters()).device
    print(f"Model device: {model_device}")
    
    # ãƒ†ã‚¹ãƒˆå…¥åŠ›ã‚’ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ãƒ‡ãƒã‚¤ã‚¹ã«é…ç½®
    test_input = torch.randn(1, 3, 512, 512).clamp(-1, 1).to(model_device)
    print(f"Input device: {test_input.device}")
    
    try:
        with torch.no_grad():
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            start_time = time.time()
            posterior = vae.encode(test_input)
            latents = posterior.latent_dist.mode()
            encode_time = time.time() - start_time
            
            # ãƒ‡ã‚³ãƒ¼ãƒ‰
            start_time = time.time()
            decoded = vae.decode(latents).sample.clamp(-1, 1)
            decode_time = time.time() - start_time
            
        print(f"âœ… Device consistency maintained")
        print(f"   Latent device: {latents.device}")
        print(f"   Decoded device: {decoded.device}")
        print(f"   Encode time: {encode_time:.3f}s")
        print(f"   Decode time: {decode_time:.3f}s")
        print(f"   Total time: {encode_time + decode_time:.3f}s")
        
        return True
        
    except Exception as e:
        print(f"âŒ Device handling failed: {e}")
        return False

def test_reconstruction_quality_fixed(original, reconstructed):
    """ä¿®æ­£ç‰ˆå†æ§‹æˆå“è³ªãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 50)
    print("TEST 4: Reconstruction Quality (Fixed)")
    print("=" * 50)
    
    if reconstructed is None:
        print("âŒ No reconstructed image to test")
        return
    
    # ãƒ‡ãƒã‚¤ã‚¹çµ±ä¸€
    if original.device != reconstructed.device:
        reconstructed = reconstructed.to(original.device)
    
    # MSEæå¤±è¨ˆç®—
    mse_loss = torch.nn.functional.mse_loss(original, reconstructed)
    print(f"MSE Loss: {mse_loss.item():.6f}")
    
    # MAEæå¤±è¨ˆç®—
    mae_loss = torch.nn.functional.l1_loss(original, reconstructed)
    print(f"MAE Loss: {mae_loss.item():.6f}")
    
    # å€¤ç¯„å›²ãƒã‚§ãƒƒã‚¯
    if torch.all(reconstructed >= -1.0) and torch.all(reconstructed <= 1.0):
        print("âœ… Output range within bounds [-1.0, 1.0]")
    else:
        print(f"âŒ Output range issue: [{reconstructed.min():.3f}, {reconstructed.max():.3f}]")
    
    # å“è³ªæŒ‡æ¨™
    if mse_loss < 1.0:
        print("âœ… Reconstruction quality acceptable (MSE < 1.0)")
    else:
        print("âš ï¸  High reconstruction error")
    
    # PSNRè¨ˆç®—ï¼ˆä¿®æ­£ç‰ˆï¼‰
    if mse_loss > 0:
        psnr = 20 * torch.log10(2.0 / torch.sqrt(mse_loss))
        print(f"PSNR: {psnr.item():.2f} dB")
    else:
        print("PSNR: âˆ dB (perfect reconstruction)")
    
    # ãƒ”ã‚¯ã‚»ãƒ«å˜ä½ã®çµ±è¨ˆ
    diff = torch.abs(original - reconstructed)
    print(f"Max pixel difference: {diff.max():.3f}")
    print(f"Mean pixel difference: {diff.mean():.3f}")

def test_batch_processing(vae):
    """ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 50)
    print("TEST 5: Batch Processing")
    print("=" * 50)
    
    device = next(vae.parameters()).device
    batch_sizes = [1, 2, 4, 8]
    
    for batch_size in batch_sizes:
        try:
            # ãƒãƒƒãƒãƒ†ã‚¹ãƒˆ
            test_batch = torch.randn(batch_size, 3, 512, 512).clamp(-1, 1).to(device)
            
            start_time = time.time()
            with torch.no_grad():
                latents = vae.encode(test_batch).latent_dist.mode()
                decoded = vae.decode(latents).sample.clamp(-1, 1)
            
            batch_time = time.time() - start_time
            time_per_image = batch_time / batch_size
            
            print(f"âœ… Batch size {batch_size}: {batch_time:.3f}s total, {time_per_image:.3f}s/image")
            
        except Exception as e:
            print(f"âŒ Batch size {batch_size} failed: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³æ¤œè¨¼å®Ÿè¡Œï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    print("ğŸ§ª SD 1.4 VAE Library Verification (Fixed)")
    print("Purpose: Verify Diffusers library with problem fixes")
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA version: {torch.version.cuda}")
        print(f"GPU: {torch.cuda.get_device_name()}")
    print()
    
    # 1. ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•é¸æŠä»˜ãï¼‰
    vae = test_model_loading()
    if vae is None:
        print("\nâŒ Critical failure: Cannot proceed without model")
        return False
    
    # 2. ä¿®æ­£ç‰ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰
    original, reconstructed = test_encode_decode_with_clamping(vae)
    
    # 3. ãƒ‡ãƒã‚¤ã‚¹å‡¦ç†ãƒ†ã‚¹ãƒˆ
    device_test_passed = test_proper_device_handling(vae)
    
    # 4. ä¿®æ­£ç‰ˆå“è³ªãƒ†ã‚¹ãƒˆ  
    test_reconstruction_quality_fixed(original, reconstructed)
    
    # 5. ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ
    test_batch_processing(vae)
    
    print("\n" + "=" * 50)
    print("ğŸ FIXED VERIFICATION COMPLETE")
    print("=" * 50)
    print("Key improvements in this version:")
    print("  âœ… Proper device handling (CPU/GPU)")
    print("  âœ… Output range clamping to [-1, 1]")
    print("  âœ… Consistent tensor devices")
    print("  âœ… Batch processing validation")
    
    if device_test_passed and original is not None and reconstructed is not None:
        print("\nğŸ‰ All major issues fixed! Library is working correctly.")
        return True
    else:
        print("\nâš ï¸  Some issues remain, but library is largely functional.")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)