# èƒŒæ™¯
Stable Diffusionã®ç”»åƒè£œå®Œã«ãŠã„ã¦ã€VAEã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã«ã‚ˆã‚‹æ½œåœ¨è¡¨ç¾ã®è³ªã®ä½ã•ãŒæœ€çµ‚çš„ãªè£œå®Œç”»åƒã®å“è³ªã‚’åˆ¶é™ã—ã¦ã„ã¾ã™ã€‚

# ç›®çš„
VAEã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®æ€§èƒ½é™ç•Œã‚’å…‹æœã—ã€å…¥åŠ›ç”»åƒã®æƒ…å ±ã‚’æœ€å¤§é™ã«ä¿æŒã—ãŸç†æƒ³çš„ãªæ½œåœ¨è¡¨ç¾ã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚’ç¢ºç«‹ã—ã¾ã™ã€‚

# æ–¹æ³•
VAEã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã«ã‚ˆã‚‹åˆæœŸæ½œåœ¨è¡¨ç¾ã«å¯¾ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ€ã‹ã‚‰ã®å†æ§‹æˆèª¤å·®ã‚’æœ€å°åŒ–ã™ã‚‹äº‹å¾Œæœ€é©åŒ–ã‚’å®Ÿè¡Œã—ã€è£œå®Œã‚¿ã‚¹ã‚¯ã«æœ€é©ãªæ½œåœ¨è¡¨ç¾ã‚’ç²å¾—ã—ã¾ã™ã€‚

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ³

## âœ… å…¨ãƒ•ã‚§ãƒ¼ã‚ºå®Œäº†æ¸ˆã¿
- **ãƒ•ã‚§ãƒ¼ã‚º1**: PyPIãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é…å¸ƒï¼ˆ`vae-toolkit` v0.1.0ï¼‰
- **ãƒ•ã‚§ãƒ¼ã‚º2**: ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒãƒƒãƒå‡¦ç†ã€ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰
- **ãƒ•ã‚§ãƒ¼ã‚º3**: é«˜åº¦å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆLPIPS/æ”¹è‰¯SSIM/FID/çµ±åˆè©•ä¾¡APIï¼‰

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 
```
src/generative_latent_optimization/
â”œâ”€â”€ optimization/latent_optimizer.py    # VAEæœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
â”œâ”€â”€ metrics/                            # è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
â”‚   â”œâ”€â”€ image_metrics.py               # PSNR/SSIM/MSE/MAE
â”‚   â”œâ”€â”€ individual_metrics.py          # LPIPS/æ”¹è‰¯SSIM
â”‚   â”œâ”€â”€ dataset_metrics.py             # FID
â”‚   â””â”€â”€ metrics_integration.py         # çµ±åˆè¨ˆç®—
â”œâ”€â”€ evaluation/                         # è©•ä¾¡API
â”‚   â”œâ”€â”€ dataset_evaluator.py           # åŒ…æ‹¬çš„è©•ä¾¡
â”‚   â””â”€â”€ simple_evaluator.py            # ç°¡æ½”API
â”œâ”€â”€ dataset/                            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†
â”œâ”€â”€ workflows/batch_processing.py       # é«˜ãƒ¬ãƒ™ãƒ«API
â””â”€â”€ utils/visualization/                # I/Oãƒ»å¯è¦–åŒ–
```

## âœ… ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦
```
BSDS500ç”»åƒ â†’ VAEå‰å‡¦ç† â†’ æœ€é©åŒ– â†’ ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ â†’ å“è³ªè©•ä¾¡
```

## å®Œæˆæ©Ÿèƒ½
- **VAEæœ€é©åŒ–**: Adamæœ€é©åŒ–å™¨ã€åæŸåˆ¤å®šã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: PyTorch/PNGå½¢å¼ã€ãƒãƒƒãƒå‡¦ç†
- **å“è³ªè©•ä¾¡**: PSNR/SSIM/LPIPS/FIDã€çµ±è¨ˆåˆ†æã€ç¾ã—ã„ãƒ¬ãƒãƒ¼ãƒˆ

## ğŸš€ åˆ©ç”¨ä¾‹

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
```python
from src.generative_latent_optimization.workflows import optimize_bsds500_test

# ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
datasets = optimize_bsds500_test(
    output_path='./my_dataset',
    max_images=10,
    create_pytorch=True,
    create_png=True
)
```

### å“è³ªè©•ä¾¡
```python
from src.generative_latent_optimization import SimpleAllMetricsEvaluator

# ãƒ¯ãƒ³ã‚³ãƒãƒ³ãƒ‰å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è©•ä¾¡
evaluator = SimpleAllMetricsEvaluator(device='cuda')
results = evaluator.evaluate_dataset_all_metrics('./created', './original')
evaluator.print_summary(results)
# ğŸ“Š All Metrics Evaluation Summary
# ğŸ¯ Dataset-level FID Score: 12.34
# ğŸ† Overall Quality: Excellent âœ¨
```

# ç’°å¢ƒãƒ»ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹

## é–‹ç™ºç’°å¢ƒ
```bash
NIXPKGS_ALLOW_UNFREE=1 nix develop --impure
```

## BSDS500ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
```bash
$BSDS500_PATH/train/  # 200æš
$BSDS500_PATH/val/    # 100æš
$BSDS500_PATH/test/   # 200æš
```

## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ©ç”¨
```python
from src.generative_latent_optimization.dataset import load_optimized_dataset

# PyTorchãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
dataset = load_optimized_dataset('./dataset.pt')
dataloader = dataset.create_dataloader(batch_size=4, shuffle=True)
```

# ğŸ”„ æ¬¡æœŸé–‹ç™ºæ§‹æƒ³

## Phase 4ä»¥é™
- **å®Ÿç”¨åŒ–**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã€Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- **ç ”ç©¶å¿œç”¨**: ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¯¾å¿œã€è«–æ–‡æº–å‚™
- **ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹**: åŒ…æ‹¬çš„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹ç¯‰

## ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
```bash
NIXPKGS_ALLOW_UNFREE=1 nix develop --impure -c uv run python test_simple_evaluator.py
```

# important-instruction-reminders
Do what has been asked; nothing more, nothing less.
NEVER create files unless they're absolutely necessary for achieving your goal.
ALWAYS prefer editing an existing file to creating a new one.
NEVER proactively create documentation files (*.md) or README files. Only create documentation files if explicitly requested by the User.
